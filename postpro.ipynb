{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404752a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ====================== Inverse Transform Functions ======================\n",
    "def unpad_volume(padded_volume, original_shape):\n",
    "    current_shape = padded_volume.shape\n",
    "    \n",
    "    # Calculate how much to remove from each dimension\n",
    "    remove_z = current_shape[0] - original_shape[0]\n",
    "    remove_y = current_shape[1] - original_shape[1] \n",
    "    remove_x = current_shape[2] - original_shape[2]\n",
    "    \n",
    "    if remove_z < 0 or remove_y < 0 or remove_x < 0:\n",
    "        print(f\"‚ùå Cannot unpad: current shape {current_shape} is smaller than target {original_shape}\")\n",
    "        return padded_volume\n",
    "    \n",
    "    # Calculate start and end indices for cropping (centered)\n",
    "    start_z = remove_z // 2\n",
    "    end_z = start_z + original_shape[0]\n",
    "    \n",
    "    start_y = remove_y // 2\n",
    "    end_y = start_y + original_shape[1]\n",
    "    \n",
    "    start_x = remove_x // 2\n",
    "    end_x = start_x + original_shape[2]\n",
    "    \n",
    "    # Crop to original size\n",
    "    unpadded = padded_volume[start_z:end_z, start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    print(f\"üìè Unpadding from {current_shape} to {original_shape}\")\n",
    "    \n",
    "    return unpadded\n",
    "\n",
    "def unresize_volume(resized_volume, original_shape, is_mask=False):\n",
    "    current_shape = resized_volume.shape\n",
    "    \n",
    "    # Calculate scaling factors\n",
    "    z_scale = original_shape[0] / current_shape[0]\n",
    "    y_scale = original_shape[1] / current_shape[1]\n",
    "    x_scale = original_shape[2] / current_shape[2]\n",
    "    \n",
    "    scale_factors = (z_scale, y_scale, x_scale)\n",
    "    \n",
    "    print(f\"üîÑ Resizing back from {current_shape} to {original_shape}\")\n",
    "    \n",
    "    # Use appropriate interpolation\n",
    "    if is_mask:\n",
    "        # Binary mask - use nearest neighbor\n",
    "        result = zoom(resized_volume, scale_factors, order=0, mode='nearest')\n",
    "    else:\n",
    "        # Continuous values - use linear interpolation\n",
    "        result = zoom(resized_volume, scale_factors, order=1, mode='nearest')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def denormalize_dose(normalized_dose, normalization_stats):\n",
    "    if not normalization_stats or not normalization_stats.get('normalized', False):\n",
    "        print(\"‚ö†Ô∏è No normalization stats provided, returning as-is\")\n",
    "        return normalized_dose\n",
    "    \n",
    "    method = normalization_stats.get('normalization_method', 'percentile')\n",
    "    \n",
    "    # Reverse visual enhancement if applied\n",
    "    if normalization_stats.get('visual_enhancement', False):\n",
    "        gamma = 0.7\n",
    "        normalized_dose = np.power(normalized_dose, 1.0/gamma)\n",
    "        print(f\"üé® Reversed gamma correction (gamma={1.0/gamma:.2f})\")\n",
    "    \n",
    "    # Reverse normalization based on method\n",
    "    if method == 'percentile':\n",
    "        factor = normalization_stats['normalization_factor']\n",
    "        denormalized = normalized_dose * factor\n",
    "        print(f\"üíä Denormalized dose: [0,1] -> [0, {factor:.4f}] using percentile method\")\n",
    "        \n",
    "    elif method == 'minmax':\n",
    "        min_orig = normalization_stats['min_orig']\n",
    "        max_orig = normalization_stats['max_orig']\n",
    "        denormalized = normalized_dose * (max_orig - min_orig) + min_orig\n",
    "        print(f\"üíä Denormalized dose: [0,1] -> [{min_orig:.4f}, {max_orig:.4f}] using min-max\")\n",
    "        \n",
    "    elif method == 'fixed':\n",
    "        factor = normalization_stats['normalization_factor']\n",
    "        denormalized = normalized_dose * factor\n",
    "        print(f\"üíä Denormalized dose: [0,1] -> [0, {factor:.4f}] using fixed method\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Unknown normalization method: {method}\")\n",
    "        denormalized = normalized_dose\n",
    "    \n",
    "    return denormalized\n",
    "\n",
    "def unrescale_ct_from_range(rescaled_ct, min_hu=-1000, max_hu=1000, input_range=(0, 255)):\n",
    "    min_in, max_in = input_range\n",
    "    \n",
    "    # Convert back to HU\n",
    "    ct_hu = (rescaled_ct - min_in) / (max_in - min_in) * (max_hu - min_hu) + min_hu\n",
    "    \n",
    "    print(f\"üîÑ Unrescaled CT: [{min_in}, {max_in}] -> [{min_hu}, {max_hu}] HU\")\n",
    "    \n",
    "    return ct_hu\n",
    "\n",
    "# ====================== Complete Postprocessing Pipeline ======================\n",
    "def postprocess_prediction(predicted_volume, original_metadata, volume_type='dose', \n",
    "                         output_path=None, save_npy=True, show_visualization=True):\n",
    "    \n",
    "    print(f\"üîÑ Starting postprocessing for {volume_type}...\")\n",
    "    print(f\"üìä Input shape: {predicted_volume.shape}\")\n",
    "    \n",
    "    # Step 1: Denormalize if needed\n",
    "    processed_volume = predicted_volume.copy()\n",
    "    \n",
    "    if volume_type == 'dose' and 'normalization_stats' in original_metadata:\n",
    "        processed_volume = denormalize_dose(processed_volume, original_metadata['normalization_stats'])\n",
    "    elif volume_type == 'ct' and original_metadata.get('rescaled', False):\n",
    "        min_hu = original_metadata.get('min_hu', -1000)\n",
    "        max_hu = original_metadata.get('max_hu', 1000)\n",
    "        input_range = original_metadata.get('rescale_range', (0, 255))\n",
    "        processed_volume = unrescale_ct_from_range(processed_volume, min_hu, max_hu, input_range)\n",
    "    \n",
    "    # Step 2: Unpad if volume was padded\n",
    "    if 'original_shape_before_padding' in original_metadata:\n",
    "        target_shape = original_metadata['original_shape_before_padding']\n",
    "        processed_volume = unpad_volume(processed_volume, target_shape)\n",
    "    \n",
    "    # Step 3: Unresize to original dimensions\n",
    "    if 'original_shape' in original_metadata:\n",
    "        original_shape = original_metadata['original_shape']\n",
    "        is_mask = (volume_type == 'mask')\n",
    "        processed_volume = unresize_volume(processed_volume, original_shape, is_mask)\n",
    "    \n",
    "    print(f\"‚úÖ Final shape: {processed_volume.shape}\")\n",
    "    \n",
    "    # Step 4: Save as .npy if requested\n",
    "    if save_npy and output_path:\n",
    "        np.save(output_path, processed_volume.astype(np.float32))\n",
    "        print(f\"üíæ Saved postprocessed volume to: {output_path}\")\n",
    "    \n",
    "    # Step 5: Show visualization if requested\n",
    "    if show_visualization:\n",
    "        visualize_three_planes(processed_volume, volume_type, \n",
    "                             title=f\"Postprocessed {volume_type.upper()}\")\n",
    "    \n",
    "    return processed_volume\n",
    "\n",
    "# ====================== Visualization Functions ======================\n",
    "def visualize_three_planes(volume, volume_type='dose', slice_indices=None, title=\"Medical Volume\"):\n",
    "    \n",
    "    if volume is None or len(volume.shape) != 3:\n",
    "        print(\"‚ùå Invalid volume for visualization\")\n",
    "        return\n",
    "    \n",
    "    z_size, y_size, x_size = volume.shape\n",
    "    \n",
    "    # Default to middle slices if not specified\n",
    "    if slice_indices is None:\n",
    "        slice_indices = {\n",
    "            'axial': z_size // 2,\n",
    "            'coronal': y_size // 2, \n",
    "            'sagittal': x_size // 2\n",
    "        }\n",
    "    \n",
    "    # Choose colormap based on volume type\n",
    "    if volume_type == 'dose':\n",
    "        cmap = 'hot'\n",
    "        vmin, vmax = 0, np.percentile(volume, 95)  # Avoid outliers\n",
    "    elif volume_type == 'ct':\n",
    "        cmap = 'gray'\n",
    "        vmin, vmax = np.percentile(volume, 1), np.percentile(volume, 99)\n",
    "    elif volume_type == 'mask':\n",
    "        cmap = 'gray'\n",
    "        vmin, vmax = 0, 1\n",
    "    else:\n",
    "        cmap = 'viridis'\n",
    "        vmin, vmax = np.min(volume), np.max(volume)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Axial view (xy plane)\n",
    "    axial_slice = volume[slice_indices['axial'], :, :]\n",
    "    im1 = axes[0].imshow(axial_slice, cmap=cmap, vmin=vmin, vmax=vmax, origin='lower')\n",
    "    axes[0].set_title(f'Axial (z={slice_indices[\"axial\"]})')\n",
    "    axes[0].set_xlabel('X')\n",
    "    axes[0].set_ylabel('Y')\n",
    "    axes[0].axis('on')\n",
    "    \n",
    "    # Coronal view (xz plane) \n",
    "    coronal_slice = volume[:, slice_indices['coronal'], :].T  # Transpose for correct orientation\n",
    "    im2 = axes[1].imshow(coronal_slice, cmap=cmap, vmin=vmin, vmax=vmax, origin='lower')\n",
    "    axes[1].set_title(f'Coronal (y={slice_indices[\"coronal\"]})')\n",
    "    axes[1].set_xlabel('X')\n",
    "    axes[1].set_ylabel('Z')\n",
    "    axes[1].axis('on')\n",
    "    \n",
    "    # Sagittal view (yz plane)\n",
    "    sagittal_slice = volume[:, :, slice_indices['sagittal']].T  # Transpose for correct orientation\n",
    "    im3 = axes[2].imshow(sagittal_slice, cmap=cmap, vmin=vmin, vmax=vmax, origin='lower')\n",
    "    axes[2].set_title(f'Sagittal (x={slice_indices[\"sagittal\"]})')\n",
    "    axes[2].set_xlabel('Y') \n",
    "    axes[2].set_ylabel('Z')\n",
    "    axes[2].axis('on')\n",
    "    \n",
    "    # Add colorbars\n",
    "    plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "    plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "    plt.colorbar(im3, ax=axes[2], shrink=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"üìä {title} Statistics:\")\n",
    "    print(f\"   Shape: {volume.shape}\")\n",
    "    print(f\"   Range: [{np.min(volume):.4f}, {np.max(volume):.4f}]\")\n",
    "    print(f\"   Mean: {np.mean(volume):.4f}\")\n",
    "    print(f\"   Std: {np.std(volume):.4f}\")\n",
    "\n",
    "def compare_original_vs_processed(original_volume, processed_volume, volume_type='dose'):\n",
    "    \"\"\"\n",
    "    Side-by-side comparison of original vs processed volume\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f'Original vs Processed {volume_type.upper()}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Choose middle slices\n",
    "    z_mid = original_volume.shape[0] // 2\n",
    "    y_mid = original_volume.shape[1] // 2 \n",
    "    x_mid = original_volume.shape[2] // 2\n",
    "    \n",
    "    # Colormap settings\n",
    "    if volume_type == 'dose':\n",
    "        cmap = 'hot'\n",
    "        vmin_orig = 0\n",
    "        vmax_orig = np.percentile(original_volume, 95)\n",
    "        vmin_proc = 0\n",
    "        vmax_proc = np.percentile(processed_volume, 95)\n",
    "    else:\n",
    "        cmap = 'gray'\n",
    "        vmin_orig = np.percentile(original_volume, 1)\n",
    "        vmax_orig = np.percentile(original_volume, 99)\n",
    "        vmin_proc = np.percentile(processed_volume, 1)\n",
    "        vmax_proc = np.percentile(processed_volume, 99)\n",
    "    \n",
    "    views = ['Axial', 'Coronal', 'Sagittal']\n",
    "    \n",
    "    for i, view in enumerate(views):\n",
    "        if view == 'Axial':\n",
    "            orig_slice = original_volume[z_mid, :, :]\n",
    "            proc_slice = processed_volume[z_mid, :, :]\n",
    "        elif view == 'Coronal':\n",
    "            orig_slice = original_volume[:, y_mid, :].T\n",
    "            proc_slice = processed_volume[:, y_mid, :].T\n",
    "        else:  # Sagittal\n",
    "            orig_slice = original_volume[:, :, x_mid].T\n",
    "            proc_slice = processed_volume[:, :, x_mid].T\n",
    "        \n",
    "        # Original\n",
    "        axes[0, i].imshow(orig_slice, cmap=cmap, vmin=vmin_orig, vmax=vmax_orig, origin='lower')\n",
    "        axes[0, i].set_title(f'Original {view}')\n",
    "        axes[0, i].axis('on')\n",
    "        \n",
    "        # Processed\n",
    "        axes[1, i].imshow(proc_slice, cmap=cmap, vmin=vmin_proc, vmax=vmax_proc, origin='lower')\n",
    "        axes[1, i].set_title(f'Processed {view}')\n",
    "        axes[1, i].axis('on')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ====================== Batch Processing Function ======================\n",
    "def postprocess_batch(predictions_dir, metadata_dir, output_dir, volume_type='dose'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    prediction_files = sorted([f for f in os.listdir(predictions_dir) if f.endswith('.npy')])\n",
    "    \n",
    "    print(f\"üîÑ Processing {len(prediction_files)} predictions...\")\n",
    "    \n",
    "    for pred_file in prediction_files:\n",
    "        print(f\"\\nüìÅ Processing: {pred_file}\")\n",
    "        \n",
    "        # Load prediction\n",
    "        pred_path = os.path.join(predictions_dir, pred_file)\n",
    "        prediction = np.load(pred_path)\n",
    "        \n",
    "        # Load metadata (assuming same name but .json extension)\n",
    "        meta_file = pred_file.replace('.npy', '_metadata.json')\n",
    "        meta_path = os.path.join(metadata_dir, meta_file)\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            with open(meta_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        except:\n",
    "            print(f\"‚ö†Ô∏è Could not load metadata for {pred_file}, using default\")\n",
    "            metadata = create_sample_metadata()\n",
    "        \n",
    "        # Postprocess\n",
    "        output_path = os.path.join(output_dir, f\"postprocessed_{pred_file}\")\n",
    "        \n",
    "        postprocessed = postprocess_prediction(\n",
    "            predicted_volume=prediction,\n",
    "            original_metadata=metadata,\n",
    "            volume_type=volume_type,\n",
    "            output_path=output_path,\n",
    "            save_npy=True,\n",
    "            show_visualization=False  # Don't show vis for batch processing\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Saved: {output_path}\")\n",
    "    \n",
    "    print(f\"\\nüéâ Batch postprocessing complete! Results saved to: {output_dir}\")\n",
    "\n",
    "# ====================== DICOM Reference Functions ======================\n",
    "\n",
    "def read_dicom_metadata(dicom_folder_path):\n",
    "    try:\n",
    "        import pydicom\n",
    "        import glob\n",
    "    except ImportError:\n",
    "        print(\"‚ùå pydicom not installed. Install with: pip install pydicom\")\n",
    "        return None\n",
    "    \n",
    "    # Find all DICOM files\n",
    "    dcm_files = glob.glob(os.path.join(dicom_folder_path, \"*.dcm\"))\n",
    "    if not dcm_files:\n",
    "        print(f\"‚ùå No DICOM files found in {dicom_folder_path}\")\n",
    "        return None\n",
    "    \n",
    "    dcm_files.sort()  # Sort by filename\n",
    "    print(f\"üìÅ Found {len(dcm_files)} DICOM files\")\n",
    "    \n",
    "    # Read first file to get metadata\n",
    "    first_dcm = pydicom.dcmread(dcm_files[0])\n",
    "    \n",
    "    # Get image dimensions\n",
    "    rows = int(first_dcm.Rows)\n",
    "    columns = int(first_dcm.Columns)\n",
    "    num_slices = len(dcm_files)\n",
    "    \n",
    "    # Get pixel spacing\n",
    "    try:\n",
    "        pixel_spacing = first_dcm.PixelSpacing  # [row_spacing, col_spacing]\n",
    "        slice_thickness = float(first_dcm.SliceThickness)\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Could not read spacing information, using defaults\")\n",
    "        pixel_spacing = [1.0, 1.0]\n",
    "        slice_thickness = 1.0\n",
    "    \n",
    "    # Create metadata dictionary\n",
    "    metadata = {\n",
    "        'original_shape': (num_slices, rows, columns),  # (z, y, x)\n",
    "        'pixel_spacing': [float(pixel_spacing[0]), float(pixel_spacing[1])],  # [y, x]\n",
    "        'slice_thickness': slice_thickness,  # z\n",
    "        'num_slices': num_slices,\n",
    "        'matrix_size': (rows, columns),\n",
    "        'dicom_folder': dicom_folder_path,\n",
    "        'dicom_files': dcm_files\n",
    "    }\n",
    "    \n",
    "    print(f\"üìä DICOM Metadata:\")\n",
    "    print(f\"   Original shape: {metadata['original_shape']}\")\n",
    "    print(f\"   Pixel spacing: {metadata['pixel_spacing']} mm\")\n",
    "    print(f\"   Slice thickness: {metadata['slice_thickness']} mm\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def create_metadata_from_dicom(dicom_folder_path, preprocessing_params=None):\n",
    "    # Read DICOM metadata\n",
    "    dicom_meta = read_dicom_metadata(dicom_folder_path)\n",
    "    if dicom_meta is None:\n",
    "        return None\n",
    "    \n",
    "    # Default preprocessing parameters if not provided\n",
    "    if preprocessing_params is None:\n",
    "        preprocessing_params = {\n",
    "            'target_size': (256, 256),  # Resize target\n",
    "            'target_slices': None,      # No slice padding/cropping\n",
    "            'normalization_method': 'percentile',\n",
    "            'percentile': 95,\n",
    "            'rescale_ct': True,\n",
    "            'min_hu': -1000,\n",
    "            'max_hu': 1000,\n",
    "            'rescale_range': (0, 255)\n",
    "        }\n",
    "    \n",
    "    # Create complete metadata\n",
    "    complete_metadata = {\n",
    "        # Original DICOM info\n",
    "        'original_shape': dicom_meta['original_shape'],\n",
    "        'pixel_spacing': dicom_meta['pixel_spacing'],\n",
    "        'slice_thickness': dicom_meta['slice_thickness'],\n",
    "        'dicom_folder': dicom_meta['dicom_folder'],\n",
    "        \n",
    "        # Preprocessing parameters\n",
    "        'target_size': preprocessing_params['target_size'],\n",
    "        'target_slices': preprocessing_params.get('target_slices'),\n",
    "        \n",
    "        # For CT rescaling\n",
    "        'rescaled': preprocessing_params.get('rescale_ct', False),\n",
    "        'min_hu': preprocessing_params.get('min_hu', -1000),\n",
    "        'max_hu': preprocessing_params.get('max_hu', 1000),\n",
    "        'rescale_range': preprocessing_params.get('rescale_range', (0, 255)),\n",
    "        \n",
    "        # For dose normalization (will be filled during postprocessing)\n",
    "        'normalization_stats': None\n",
    "    }\n",
    "    \n",
    "    # Calculate intermediate shapes for proper unpadding/unresizing\n",
    "    original_shape = dicom_meta['original_shape']\n",
    "    target_size = preprocessing_params['target_size']\n",
    "    target_slices = preprocessing_params.get('target_slices')\n",
    "    \n",
    "    # Shape after resizing XY but before Z padding\n",
    "    resized_shape = (original_shape[0], target_size[0], target_size[1])\n",
    "    complete_metadata['original_shape_before_padding'] = resized_shape\n",
    "    \n",
    "    # Final preprocessed shape\n",
    "    if target_slices:\n",
    "        final_shape = (target_slices, target_size[0], target_size[1])\n",
    "    else:\n",
    "        final_shape = resized_shape\n",
    "    complete_metadata['preprocessed_shape'] = final_shape\n",
    "    \n",
    "    print(f\"‚úÖ Created complete metadata:\")\n",
    "    print(f\"   Original: {original_shape}\")\n",
    "    print(f\"   After resize: {resized_shape}\")\n",
    "    print(f\"   Final preprocessed: {final_shape}\")\n",
    "    \n",
    "    return complete_metadata\n",
    "\n",
    "def postprocess_with_dicom_reference(predicted_volume, dicom_folder_path, \n",
    "                                   volume_type='dose', preprocessing_params=None,\n",
    "                                   output_path=None, save_npy=True, show_visualization=True):\n",
    "    \n",
    "    print(f\"üîÑ Postprocessing with DICOM reference: {dicom_folder_path}\")\n",
    "    \n",
    "    # Create metadata from DICOM\n",
    "    metadata = create_metadata_from_dicom(dicom_folder_path, preprocessing_params)\n",
    "    if metadata is None:\n",
    "        print(\"‚ùå Failed to create metadata from DICOM\")\n",
    "        return None\n",
    "    \n",
    "    # Add normalization stats if this is a dose volume\n",
    "    if volume_type == 'dose':\n",
    "        # You might want to provide actual normalization stats here\n",
    "        # For now, using sample stats\n",
    "        metadata['normalization_stats'] = {\n",
    "            'normalized': True,\n",
    "            'normalization_method': 'percentile',\n",
    "            'normalization_factor': 7.5,  # This should come from your preprocessing\n",
    "            'percentile_used': 95,\n",
    "            'visual_enhancement': True,\n",
    "            'min_orig': 0.0,\n",
    "            'max_orig': 8.2,\n",
    "            'mean_orig': 1.5\n",
    "        }\n",
    "    \n",
    "    # Use the standard postprocessing pipeline\n",
    "    result = postprocess_prediction(\n",
    "        predicted_volume=predicted_volume,\n",
    "        original_metadata=metadata,\n",
    "        volume_type=volume_type,\n",
    "        output_path=output_path,\n",
    "        save_npy=save_npy,\n",
    "        show_visualization=show_visualization\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def load_and_compare_with_dicom(predicted_volume, dicom_folder_path, \n",
    "                               volume_type='dose', preprocessing_params=None):\n",
    "    try:\n",
    "        import pydicom\n",
    "        import glob\n",
    "    except ImportError:\n",
    "        print(\"‚ùå pydicom not installed. Install with: pip install pydicom\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"üìä Loading and comparing with DICOM reference...\")\n",
    "    \n",
    "    # Postprocess prediction\n",
    "    postprocessed = postprocess_with_dicom_reference(\n",
    "        predicted_volume=predicted_volume,\n",
    "        dicom_folder_path=dicom_folder_path,\n",
    "        volume_type=volume_type,\n",
    "        preprocessing_params=preprocessing_params,\n",
    "        show_visualization=False  # We'll do custom comparison\n",
    "    )\n",
    "    \n",
    "    if postprocessed is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Load original DICOM for comparison (if it's CT)\n",
    "    if volume_type == 'ct':\n",
    "        dcm_files = sorted(glob.glob(os.path.join(dicom_folder_path, \"*.dcm\")))\n",
    "        original_volume = []\n",
    "        \n",
    "        for dcm_file in dcm_files:\n",
    "            dcm = pydicom.dcmread(dcm_file)\n",
    "            original_volume.append(dcm.pixel_array)\n",
    "        \n",
    "        original_volume = np.array(original_volume)\n",
    "        \n",
    "        # Convert to HU if needed\n",
    "        if hasattr(pydicom.dcmread(dcm_files[0]), 'RescaleSlope'):\n",
    "            slope = float(pydicom.dcmread(dcm_files[0]).RescaleSlope)\n",
    "            intercept = float(pydicom.dcmread(dcm_files[0]).RescaleIntercept)\n",
    "            original_volume = original_volume * slope + intercept\n",
    "        \n",
    "        print(f\"üìä Loaded original DICOM: {original_volume.shape}\")\n",
    "        \n",
    "        # Compare\n",
    "        compare_original_vs_processed(original_volume, postprocessed, volume_type)\n",
    "        \n",
    "        return original_volume, postprocessed\n",
    "    \n",
    "    else:\n",
    "        # For dose/mask, just show the postprocessed result\n",
    "        visualize_three_planes(postprocessed, volume_type, \n",
    "                             title=f\"Postprocessed {volume_type.upper()}\")\n",
    "        return None, postprocessed\n",
    "\n",
    "# ====================== Jupyter Notebook Usage Examples ======================\n",
    "def jupyter_example_with_dicom_reference():\n",
    "    \"\"\"\n",
    "    Example using DICOM reference - most accurate method\n",
    "    \"\"\"\n",
    "    print(\"üè• DICOM Reference Example\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Example usage\n",
    "    dicom_folder = \"/path/to/original/dicom/folder\"\n",
    "    prediction_file = \"/path/to/model/prediction.npy\"\n",
    "    \n",
    "    # Define preprocessing parameters that were used\n",
    "    preprocessing_params = {\n",
    "        'target_size': (256, 256),\n",
    "        'target_slices': 64,  # or None if no Z padding was used\n",
    "        'rescale_ct': True,\n",
    "        'min_hu': -1000,\n",
    "        'max_hu': 1000,\n",
    "        'rescale_range': (0, 255),\n",
    "        'normalization_method': 'percentile',\n",
    "        'percentile': 95\n",
    "    }\n",
    "    \n",
    "    # Load prediction\n",
    "    prediction = np.load(prediction_file)\n",
    "    \n",
    "    # Postprocess using DICOM reference\n",
    "    result = postprocess_with_dicom_reference(\n",
    "        predicted_volume=prediction,\n",
    "        dicom_folder_path=dicom_folder,\n",
    "        volume_type='dose',  # or 'ct', 'mask'\n",
    "        preprocessing_params=preprocessing_params,\n",
    "        output_path=\"dicom_referenced_result.npy\",\n",
    "        save_npy=True,\n",
    "        show_visualization=True\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def jupyter_example_quick_dicom_check(dicom_folder):\n",
    "    \"\"\"\n",
    "    Quick check of DICOM metadata\n",
    "    \"\"\"\n",
    "    print(\"üîç Quick DICOM Check\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    metadata = read_dicom_metadata(dicom_folder)\n",
    "    if metadata:\n",
    "        print(\"‚úÖ DICOM metadata loaded successfully!\")\n",
    "        return metadata\n",
    "    else:\n",
    "        print(\"‚ùå Failed to load DICOM metadata\")\n",
    "        return None\n",
    "\n",
    "def jupyter_example_with_real_data(prediction_file, metadata_dict=None):\n",
    "    print(f\"üìÅ Loading prediction from: {prediction_file}\")\n",
    "    \n",
    "    # Load your prediction\n",
    "    prediction = np.load(prediction_file)\n",
    "    print(f\"üìä Loaded prediction shape: {prediction.shape}\")\n",
    "    \n",
    "    # Use provided metadata or create sample\n",
    "    if metadata_dict is None:\n",
    "        print(\"‚ö†Ô∏è No metadata provided, using sample metadata\")\n",
    "        metadata_dict = create_sample_metadata()\n",
    "    \n",
    "    # Postprocess\n",
    "    result = postprocess_prediction(\n",
    "        predicted_volume=prediction,\n",
    "        original_metadata=metadata_dict,\n",
    "        volume_type='dose',  # Change to 'ct' or 'mask' as needed\n",
    "        output_path=\"postprocessed_result.npy\",\n",
    "        save_npy=True,\n",
    "        show_visualization=True\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def jupyter_quick_visualize(volume_path, volume_type='dose'):\n",
    "    print(f\"üëÅÔ∏è Quick visualization of: {volume_path}\")\n",
    "    \n",
    "    volume = np.load(volume_path)\n",
    "    visualize_three_planes(volume, volume_type, title=f\"{volume_type.upper()} Volume\")\n",
    "    \n",
    "    return volume\n",
    "\n",
    "def check_padding_status(original_shape, prediction_shape):\n",
    "    orig_z, orig_y, orig_x = original_shape\n",
    "    pred_z, pred_y, pred_x = prediction_shape\n",
    "    \n",
    "    print(f\"Original shape: {original_shape}\")\n",
    "    print(f\"Prediction shape: {prediction_shape}\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö XY dimensions (‡∏°‡∏±‡∏Å‡∏à‡∏∞ resize)\n",
    "    if orig_y != pred_y or orig_x != pred_x:\n",
    "        print(f\"‚úÖ XY was resized: ({orig_y}, {orig_x}) -> ({pred_y}, {pred_x})\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Z dimension\n",
    "    if orig_z == pred_z:\n",
    "        print(\"‚úÖ Z dimension unchanged - no padding\")\n",
    "        return None  # No Z padding\n",
    "    elif orig_z < pred_z:\n",
    "        print(f\"‚úÖ Z was padded: {orig_z} -> {pred_z} (added {pred_z - orig_z} slices)\")\n",
    "        return pred_z  # Return target slices\n",
    "    else:\n",
    "        print(f\"‚úÖ Z was cropped: {orig_z} -> {pred_z} (removed {orig_z - pred_z} slices)\")\n",
    "        return pred_z  # Return target slices\n",
    "\n",
    "def auto_detect_preprocessing_params(original_shape, prediction_shape, \n",
    "                                   min_hu=-1000, max_hu=1000):\n",
    "    orig_z, orig_y, orig_x = original_shape\n",
    "    pred_z, pred_y, pred_x = prediction_shape\n",
    "    \n",
    "    params = {\n",
    "        'target_size': (pred_y, pred_x),  # ‡πÉ‡∏ä‡πâ‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏≤‡∏Å prediction\n",
    "        'target_slices': pred_z if pred_z != orig_z else None,\n",
    "        'rescale_ct': True,  # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ rescale\n",
    "        'min_hu': min_hu,\n",
    "        'max_hu': max_hu,\n",
    "        'rescale_range': (0, 255),\n",
    "        'normalization_method': 'percentile',\n",
    "        'percentile': 95\n",
    "    }\n",
    "    \n",
    "    print(\"üîç Auto-detected preprocessing parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    return params\n",
    "\n",
    "def create_manual_metadata(original_shape, prediction_shape, volume_type='dose'):\n",
    "    orig_z, orig_y, orig_x = original_shape\n",
    "    pred_z, pred_y, pred_x = prediction_shape\n",
    "    \n",
    "    metadata = {\n",
    "        'original_shape': original_shape,\n",
    "        'preprocessed_shape': prediction_shape,\n",
    "        'target_size': (pred_y, pred_x),\n",
    "        'target_slices': pred_z if pred_z != orig_z else None,\n",
    "        'rescaled': True,\n",
    "        'min_hu': -1000,\n",
    "        'max_hu': 1000,\n",
    "        'rescale_range': (0, 255)\n",
    "    }\n",
    "    \n",
    "    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dose\n",
    "    if volume_type == 'dose':\n",
    "        metadata['normalization_stats'] = {\n",
    "            'normalized': True,\n",
    "            'normalization_method': 'percentile',\n",
    "            'normalization_factor': 7.5,  # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á\n",
    "            'percentile_used': 95,\n",
    "            'visual_enhancement': True,\n",
    "            'min_orig': 0.0,\n",
    "            'max_orig': 8.2,\n",
    "            'mean_orig': 1.5\n",
    "        }\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì shape ‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏≤‡∏á\n",
    "    if metadata['target_slices'] is not None:\n",
    "        # ‡∏°‡∏µ‡∏Å‡∏≤‡∏£ pad Z\n",
    "        metadata['original_shape_before_padding'] = (orig_z, pred_y, pred_x)\n",
    "    else:\n",
    "        # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£ pad Z\n",
    "        metadata['original_shape_before_padding'] = None\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def quick_postprocess(prediction_file, dicom_folder, volume_type='dose'):\n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    prediction = np.load(prediction_file)\n",
    "    metadata = read_dicom_metadata(dicom_folder)\n",
    "    \n",
    "    # Auto-detect parameters\n",
    "    params = auto_detect_preprocessing_params(\n",
    "        metadata['original_shape'], \n",
    "        prediction.shape\n",
    "    )\n",
    "    \n",
    "    # Postprocess\n",
    "    result = postprocess_with_dicom_reference(\n",
    "        predicted_volume=prediction,\n",
    "        dicom_folder_path=dicom_folder,\n",
    "        volume_type=volume_type,\n",
    "        preprocessing_params=params,\n",
    "        output_path=f\"quick_result_{volume_type}.npy\",\n",
    "        save_npy=True,\n",
    "        show_visualization=True\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e0ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Example Usage Functions ======================\n",
    "def create_sample_metadata():\n",
    "    \"\"\"\n",
    "    Create sample metadata that would typically be saved during preprocessing\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'original_shape': (64, 512, 512),  # Original CT/dose shape\n",
    "        'original_shape_before_padding': (60, 480, 480),  # Shape before padding but after resizing\n",
    "        'preprocessed_shape': (64, 256, 256),  # Final preprocessed shape\n",
    "        'target_size': (256, 256),  # XY resize target\n",
    "        'target_slices': 64,  # Z padding/cropping target\n",
    "        'rescaled': True,  # Whether CT was rescaled\n",
    "        'min_hu': -1000,\n",
    "        'max_hu': 1000,\n",
    "        'rescale_range': (0, 255),\n",
    "        'normalization_stats': {  # For dose normalization\n",
    "            'normalized': True,\n",
    "            'normalization_method': 'percentile',\n",
    "            'normalization_factor': 7.0,\n",
    "            'percentile_used': 95,\n",
    "            'visual_enhancement': True,\n",
    "            'min_orig': 0.0,\n",
    "            'max_orig': 8.2,\n",
    "            'mean_orig': 1.5\n",
    "        }\n",
    "    }\n",
    "\n",
    "def example_usage():\n",
    "    \"\"\"\n",
    "    Example of how to use the postprocessing functions\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Example Usage of Postprocessing Pipeline\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Simulate a predicted dose volume (normalized, resized, padded)\n",
    "    predicted_dose = np.random.random((64, 256, 256)) * 0.8  # Simulated prediction [0,1]\n",
    "    \n",
    "    # Create sample metadata (this would come from your preprocessing)\n",
    "    metadata = create_sample_metadata()\n",
    "    \n",
    "    # Postprocess the prediction\n",
    "    output_path = \"postprocessed_dose.npy\"\n",
    "    \n",
    "    postprocessed_dose = postprocess_prediction(\n",
    "        predicted_volume=predicted_dose,\n",
    "        original_metadata=metadata,\n",
    "        volume_type='dose',\n",
    "        output_path=output_path,\n",
    "        save_npy=True,\n",
    "        show_visualization=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Postprocessing complete!\")\n",
    "    print(f\"üìä Original prediction shape: {predicted_dose.shape}\")\n",
    "    print(f\"üìä Final postprocessed shape: {postprocessed_dose.shape}\")\n",
    "    \n",
    "    return postprocessed_dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abfc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö DICOM metadata ‡∏Å‡πà‡∏≠‡∏ô\n",
    "metadata = read_dicom_metadata(\"/path/to/dicom/folder\")\n",
    "print(f\"Original DICOM shape: {metadata['original_shape']}\")\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ function ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n",
    "target_slices = check_padding_status(metadata['original_shape'], prediction.shape)\n",
    "# ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï preprocessing_params\n",
    "preprocessing_params['target_slices'] = target_slices\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ auto-detection\n",
    "auto_params = auto_detect_preprocessing_params(\n",
    "    metadata['original_shape'], \n",
    "    prediction.shape\n",
    ")\n",
    "\n",
    "# 2. ‡πÇ‡∏´‡∏•‡∏î prediction\n",
    "prediction = np.load(\"your_model_output.npy\")\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå preprocessing ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ target_slices ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏™‡πà None\n",
    "preprocessing_params = {\n",
    "    'target_size': (256, 256),      # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà resize ‡πÄ‡∏õ‡πá‡∏ô\n",
    "    'target_slices': None,          # ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ pad Z dimension ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à\n",
    "    'rescale_ct': True,             # ‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°‡∏ó‡∏µ‡πà rescale CT\n",
    "    'min_hu': -1000,                # ‡∏ä‡πà‡∏ß‡∏á HU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
    "    'max_hu': 1000,\n",
    "    'normalization_method': 'percentile',\n",
    "    'percentile': 95\n",
    "}\n",
    "\n",
    "# 4. Postprocess ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å DICOM ‡πÄ‡∏î‡∏¥‡∏°\n",
    "result = postprocess_with_dicom_reference(\n",
    "    predicted_volume=prediction,\n",
    "    dicom_folder_path=\"/path/to/original/dicom/folder\",\n",
    "    volume_type='dose',\n",
    "    preprocessing_params=auto_params,\n",
    "    output_path=\"result_no_padding.npy\",\n",
    "    save_npy=True,\n",
    "    show_visualization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92cc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö Manual Metadata (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ DICOM) ============\n",
    "# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô manual metadata\n",
    "manual_meta = create_manual_metadata(\n",
    "    original_shape=(64, 512, 512),  # ‡∏£‡∏∞‡∏ö‡∏∏ shape ‡πÄ‡∏î‡∏¥‡∏°\n",
    "    prediction_shape=prediction.shape,\n",
    "    volume_type='dose'\n",
    ")\n",
    "\n",
    "result_manual = postprocess_prediction(\n",
    "    predicted_volume=prediction,\n",
    "    original_metadata=manual_meta,\n",
    "    volume_type='dose',\n",
    "    output_path=\"result_manual.npy\",\n",
    "    save_npy=True,\n",
    "    show_visualization=True\n",
    ")\n",
    "\n",
    "# ============ ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ============\n",
    "if volume_type == 'ct':\n",
    "    original, processed = load_and_compare_with_dicom(\n",
    "        predicted_volume=prediction,\n",
    "        dicom_folder_path=\"/path/to/original/dicom/folder\",\n",
    "        volume_type='ct',\n",
    "        preprocessing_params=auto_params\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
