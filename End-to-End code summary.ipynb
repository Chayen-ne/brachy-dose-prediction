{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**End-to-End Test**\n",
        "(‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô drive ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡∏°‡∏≤‡∏•‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°)"
      ],
      "metadata": {
        "id": "lDwqhT4cmOxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‡∏•‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ"
      ],
      "metadata": {
        "id": "g4i-RW8lrhsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gZuxqHZcp-dr",
        "outputId": "1130e148-c1d7-40f0-ba2d-1484a8869d51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏•‡∏á Library ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ï‡∏Å‡πÉ‡∏à ! ‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞)\n",
        "!pip install pydicom SimpleITK opencv-python-headless matplotlib"
      ],
      "metadata": {
        "id": "7EsByZEsqrg5",
        "outputId": "23cdd3d3-6c8b-41a8-d62e-920b1d197277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting SimpleITK\n",
            "  Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK, pydicom\n",
            "Successfully installed SimpleITK-2.5.3 pydicom-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå DICOM (CT images, RTSTRUCT contours, RTDOSE grid) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå Numpy Array (.npy)\n",
        "\n",
        "Align ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Grid ‡∏Ç‡∏≠‡∏á CT ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢"
      ],
      "metadata": {
        "id": "40rf3wy1rs7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import cv2\n",
        "import logging\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup Logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class BrachyDataPreprocessor:\n",
        "    def __init__(self, output_dir, target_rois):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.target_rois = [roi.lower().strip() for roi in target_rois]\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def _find_dicom_files(self, folder_path, modality):\n",
        "        \"\"\"‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå DICOM ‡πÅ‡∏ö‡∏ö Recursive\"\"\"\n",
        "        found_files = []\n",
        "        folder_path = Path(folder_path)\n",
        "\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                if file.endswith('.dcm'):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    try:\n",
        "                        # ‡∏≠‡πà‡∏≤‡∏ô Header ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß\n",
        "                        dcm = pydicom.dcmread(file_path, stop_before_pixels=True)\n",
        "                        if hasattr(dcm, 'Modality') and dcm.Modality == modality:\n",
        "                            found_files.append(pydicom.dcmread(file_path))\n",
        "                    except Exception:\n",
        "                        continue\n",
        "\n",
        "        if modality == 'CT':\n",
        "            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á CT ‡∏ï‡∏≤‡∏°‡πÅ‡∏Å‡∏ô Z\n",
        "            if found_files:\n",
        "                found_files.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
        "            return found_files\n",
        "        elif len(found_files) > 0:\n",
        "            return found_files[0]\n",
        "        return None\n",
        "\n",
        "    def process_ct(self, ct_slices):\n",
        "        \"\"\"‡πÅ‡∏õ‡∏•‡∏á CT slices ‡πÄ‡∏õ‡πá‡∏ô 3D Numpy Array\"\"\"\n",
        "        try:\n",
        "            rows, cols = ct_slices[0].Rows, ct_slices[0].Columns\n",
        "            depth = len(ct_slices)\n",
        "            volume = np.zeros((depth, rows, cols), dtype=np.float32)\n",
        "\n",
        "            for i, s in enumerate(ct_slices):\n",
        "                slope = getattr(s, 'RescaleSlope', 1.0)\n",
        "                intercept = getattr(s, 'RescaleIntercept', 0.0)\n",
        "                volume[i] = s.pixel_array.astype(np.float32) * slope + intercept\n",
        "\n",
        "            return volume\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error processing CT: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_masks(self, rs_file, ct_slices, ct_shape):\n",
        "        \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á Mask ‡∏à‡∏≤‡∏Å RTSTRUCT\"\"\"\n",
        "        masks_dict = {}\n",
        "\n",
        "        z_positions = np.array([float(s.ImagePositionPatient[2]) for s in ct_slices])\n",
        "        origin = ct_slices[0].ImagePositionPatient\n",
        "        spacing = ct_slices[0].PixelSpacing\n",
        "\n",
        "        for roi in rs_file.StructureSetROISequence:\n",
        "            name = roi.ROIName.lower().strip()\n",
        "            if name not in self.target_rois:\n",
        "                continue\n",
        "\n",
        "            roi_number = roi.ROINumber\n",
        "            mask = np.zeros(ct_shape, dtype=np.uint8)\n",
        "            contour_sequence = None\n",
        "\n",
        "            # ‡∏´‡∏≤ Contour Sequence ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö ROI Number\n",
        "            for contour in rs_file.ROIContourSequence:\n",
        "                if contour.ReferencedROINumber == roi_number:\n",
        "                    if hasattr(contour, 'ContourSequence'):\n",
        "                        contour_sequence = contour.ContourSequence\n",
        "                    break\n",
        "\n",
        "            if not contour_sequence:\n",
        "                continue\n",
        "\n",
        "\n",
        "            for contour_slice in contour_sequence:\n",
        "                if not hasattr(contour_slice, 'ContourData'): continue\n",
        "\n",
        "                points = np.array(contour_slice.ContourData).reshape(-1, 3)\n",
        "                z_coord = points[0, 2]\n",
        "\n",
        "                # ‡∏´‡∏≤ Slice ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Nearest Neighbor)\n",
        "                dist = np.abs(z_positions - z_coord)\n",
        "                slice_idx = np.argmin(dist)\n",
        "\n",
        "                if dist[slice_idx] > 2.5:\n",
        "                    continue\n",
        "\n",
        "                # ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÇ‡∏•‡∏Å (mm) -> ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏†‡∏≤‡∏û (pixel)\n",
        "                x_pixel = np.round((points[:, 0] - origin[0]) / spacing[0]).astype(np.int32)\n",
        "                y_pixel = np.round((points[:, 1] - origin[1]) / spacing[1]).astype(np.int32)\n",
        "\n",
        "                pixel_coords = np.stack([x_pixel, y_pixel], axis=1)\n",
        "                cv2.fillPoly(mask[slice_idx], [pixel_coords], 1)\n",
        "\n",
        "            masks_dict[name] = mask\n",
        "        return masks_dict\n",
        "\n",
        "    def align_dose(self, dose_dcm, ct_slices):\n",
        "        \"\"\"\n",
        "        ‚úÖ ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ Dose ‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏≤ Grid ‡∏Ç‡∏≠‡∏á CT ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏≠‡∏á\n",
        "        \"\"\"\n",
        "        logger.info(\"üîÑ Aligning dose using MANUAL TRILINEAR INTERPOLATION...\")\n",
        "\n",
        "        try:\n",
        "            # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Dose\n",
        "            dose_array = dose_dcm.pixel_array.astype(np.float32) * getattr(dose_dcm, 'DoseGridScaling', 1.0)\n",
        "\n",
        "            # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á Dose Grid\n",
        "            dose_origin = np.array(dose_dcm.ImagePositionPatient, dtype=np.float32)\n",
        "            dose_pixel_spacing = np.array(dose_dcm.PixelSpacing, dtype=np.float32)\n",
        "            if hasattr(dose_dcm, 'GridFrameOffsetVector'):\n",
        "                z_diffs = np.diff(dose_dcm.GridFrameOffsetVector)\n",
        "                dose_z_spacing = z_diffs[0] if len(z_diffs) > 0 else 1.0\n",
        "            else:\n",
        "                dose_z_spacing = 1.0 # Default\n",
        "\n",
        "            dose_spacing = np.array([dose_z_spacing, dose_pixel_spacing[1], dose_pixel_spacing[0]])\n",
        "            dose_shape = dose_array.shape\n",
        "\n",
        "            # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CT (Target Grid)\n",
        "            ct_first = ct_slices[0]\n",
        "            ct_origin = np.array(ct_first.ImagePositionPatient, dtype=np.float32)\n",
        "            ct_pixel_spacing = np.array(ct_first.PixelSpacing, dtype=np.float32)\n",
        "\n",
        "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Z spacing ‡∏Ç‡∏≠‡∏á CT\n",
        "            if len(ct_slices) > 1:\n",
        "                ct_z_spacing = abs(float(ct_slices[1].ImagePositionPatient[2]) - float(ct_slices[0].ImagePositionPatient[2]))\n",
        "            else:\n",
        "                ct_z_spacing = 1.0\n",
        "\n",
        "            ct_spacing = np.array([ct_z_spacing, ct_pixel_spacing[1], ct_pixel_spacing[0]])\n",
        "            ct_shape = (len(ct_slices), ct_first.Rows, ct_first.Columns)\n",
        "\n",
        "            # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Grid ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÜ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ó‡πà‡∏≤ CT\n",
        "            aligned_dose = np.zeros(ct_shape, dtype=np.float32)\n",
        "\n",
        "            # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î (Meshgrid) ‡∏Ç‡∏≠‡∏á CT\n",
        "            # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: \"‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡πÜ pixel ‡πÉ‡∏ô CT... ‡∏°‡∏±‡∏ô‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î‡πÑ‡∏´‡∏ô‡πÉ‡∏ô Dose?\"\n",
        "            z_idx, y_idx, x_idx = np.meshgrid(\n",
        "                np.arange(ct_shape[0]),\n",
        "                np.arange(ct_shape[1]),\n",
        "                np.arange(ct_shape[2]),\n",
        "                indexing='ij'\n",
        "            )\n",
        "\n",
        "            # 5. ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î Index CT -> Physical World (mm)\n",
        "            world_z = ct_origin[2] + z_idx * ct_spacing[0]\n",
        "            world_y = ct_origin[1] + y_idx * ct_spacing[1]\n",
        "            world_x = ct_origin[0] + x_idx * ct_spacing[2]\n",
        "\n",
        "            # 6. ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î Physical World -> Index Dose (‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°)\n",
        "            dose_z_idx = (world_z - dose_origin[2]) / dose_spacing[0]\n",
        "            dose_y_idx = (world_y - dose_origin[1]) / dose_spacing[1]\n",
        "            dose_x_idx = (world_x - dose_origin[0]) / dose_spacing[2]\n",
        "\n",
        "            # 7. ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡∏Å‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á Dose (‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏Å‡∏•‡πà‡∏≠‡∏á Dose ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 0)\n",
        "            valid_mask = (\n",
        "                (dose_z_idx >= 0) & (dose_z_idx < dose_shape[0] - 1) &\n",
        "                (dose_y_idx >= 0) & (dose_y_idx < dose_shape[1] - 1) &\n",
        "                (dose_x_idx >= 0) & (dose_x_idx < dose_shape[2] - 1)\n",
        "            )\n",
        "\n",
        "            # 8. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Trilinear Interpolation (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î Valid)\n",
        "            dz = dose_z_idx[valid_mask]\n",
        "            dy = dose_y_idx[valid_mask]\n",
        "            dx = dose_x_idx[valid_mask]\n",
        "\n",
        "            z0 = np.floor(dz).astype(int)\n",
        "            y0 = np.floor(dy).astype(int)\n",
        "            x0 = np.floor(dx).astype(int)\n",
        "\n",
        "            z1 = z0 + 1\n",
        "            y1 = y0 + 1\n",
        "            x1 = x0 + 1\n",
        "\n",
        "            # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å (Weight) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Interpolation\n",
        "            w_z = dz - z0\n",
        "            w_y = dy - y0\n",
        "            w_x = dx - x0\n",
        "\n",
        "            # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å 8 ‡∏à‡∏∏‡∏î‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á (Corner values)\n",
        "            c000 = dose_array[z0, y0, x0]\n",
        "            c001 = dose_array[z0, y0, x1]\n",
        "            c010 = dose_array[z0, y1, x0]\n",
        "            c011 = dose_array[z0, y1, x1]\n",
        "            c100 = dose_array[z1, y0, x0]\n",
        "            c101 = dose_array[z1, y0, x1]\n",
        "            c110 = dose_array[z1, y1, x0]\n",
        "            c111 = dose_array[z1, y1, x1]\n",
        "\n",
        "            # ‡∏™‡∏π‡∏ï‡∏£ Trilinear Interpolation\n",
        "            interpolated_values = (\n",
        "                c000 * (1 - w_z) * (1 - w_y) * (1 - w_x) +\n",
        "                c001 * (1 - w_z) * (1 - w_y) * w_x +\n",
        "                c010 * (1 - w_z) * w_y * (1 - w_x) +\n",
        "                c011 * (1 - w_z) * w_y * w_x +\n",
        "                c100 * w_z * (1 - w_y) * (1 - w_x) +\n",
        "                c101 * w_z * (1 - w_y) * w_x +\n",
        "                c110 * w_z * w_y * (1 - w_x) +\n",
        "                c111 * w_z * w_y * w_x\n",
        "            )\n",
        "\n",
        "            # ‡∏¢‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ‡∏Å‡∏•‡∏±‡∏ö‡∏•‡∏á‡πÑ‡∏õ‡πÉ‡∏ô Grid ‡∏Ç‡∏≠‡∏á CT\n",
        "            aligned_dose[valid_mask] = interpolated_values\n",
        "\n",
        "            logger.info(\"‚úÖ Manual alignment completed successfully.\")\n",
        "            return aligned_dose\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error aligning dose: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def run_pipeline(self, patient_folder):\n",
        "        patient_id = Path(patient_folder).name\n",
        "        save_path = self.output_dir / patient_id\n",
        "        save_path.mkdir(exist_ok=True)\n",
        "\n",
        "        logger.info(f\"üöÄ Processing Patient: {patient_id}\")\n",
        "\n",
        "        ct_slices = self._find_dicom_files(patient_folder, 'CT')\n",
        "        if not ct_slices:\n",
        "            logger.error(\"No CT Found\")\n",
        "            return\n",
        "\n",
        "        ct_vol = self.process_ct(ct_slices)\n",
        "        np.save(save_path / \"CT_raw.npy\", ct_vol)\n",
        "\n",
        "        rs_file = self._find_dicom_files(patient_folder, 'RTSTRUCT')\n",
        "        if rs_file:\n",
        "            masks = self.create_masks(rs_file, ct_slices, ct_vol.shape)\n",
        "            combined_mask = np.zeros_like(ct_vol, dtype=np.uint8)\n",
        "            for name, mask_data in masks.items():\n",
        "                np.save(save_path / f\"Mask_{name}.npy\", mask_data)\n",
        "                combined_mask = np.logical_or(combined_mask, mask_data).astype(np.uint8)\n",
        "            np.save(save_path / \"Combined_Mask.npy\", combined_mask)\n",
        "\n",
        "        dose_file = self._find_dicom_files(patient_folder, 'RTDOSE')\n",
        "        if dose_file:\n",
        "            aligned_dose = self.align_dose(dose_file, ct_slices)\n",
        "            if aligned_dose is not None:\n",
        "                np.save(save_path / \"Dose_raw.npy\", aligned_dose)\n",
        "                logger.info(\"üíæ Saved Dose_raw.npy\")"
      ],
      "metadata": {
        "id": "vsWwNXmDqsCN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= (‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ!) =================\n",
        "# 1. ‡∏ß‡∏≤‡∏á Path\n",
        "DICOM_DIR = \"/content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/FSD1_1\"  # <--- ‡πÅ‡∏Å‡πâ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ\n",
        "\n",
        "# 2. ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏ã‡∏ü‡πÑ‡∏ü‡∏•‡πå .npy\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/Data_numpy/v2/Predict\"\n",
        "\n",
        "# 3. ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ß‡∏±‡∏¢‡∏ß‡∏∞/Applicator ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
        "TARGETS = [\n",
        "    'sigmoid_ct', 'bladder_ct', 'rectum_ct', 'bowel_ct', 'hrctv_ct',\n",
        "    'Applicator1', 'Applicator2', 'Applicator3',\n",
        "    'needdle1', 'needdle2'\n",
        "]\n",
        "# ========================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"üìÇ Reading from: {DICOM_DIR}\")\n",
        "    print(f\"üíæ Saving to: {OUTPUT_DIR}\")\n",
        "\n",
        "    processor = BrachyDataPreprocessor(OUTPUT_DIR, TARGETS)\n",
        "    root_path = Path(DICOM_DIR)\n",
        "\n",
        "    if not root_path.exists():\n",
        "        print(\"‚ùå Error: ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå DICOM!\")\n",
        "    else:\n",
        "        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢‡πÑ‡∏´‡∏° (‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ)\n",
        "        subdirs = [d for d in root_path.iterdir() if d.is_dir()]\n",
        "\n",
        "        if len(subdirs) > 0:\n",
        "            print(f\"üë• Found {len(subdirs)} patient folders.\")\n",
        "            for patient_dir in subdirs:\n",
        "                processor.run_pipeline(str(patient_dir))\n",
        "        else:\n",
        "            print(\"üë§ Processing single patient folder...\")\n",
        "            processor.run_pipeline(str(root_path))\n",
        "\n",
        "    print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! \")"
      ],
      "metadata": {
        "id": "uKO0ns0Hrdz6",
        "outputId": "f6d33542-bab0-4c9a-b73a-53571588d118",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Reading from: /content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/FSD1_1\n",
            "üíæ Saving to: /content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/Data_numpy/v2/Predict\n",
            "üë§ Processing single patient folder...\n",
            "‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing for Training\n",
        "\n",
        "Clip HU [-1000, 2000], Rescale [0, 1], Normalize Dose [0, 1]"
      ],
      "metadata": {
        "id": "WIkPhb40wDu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import rotate\n",
        "from pathlib import Path\n",
        "\n",
        "class BrachyTrainingPrep:\n",
        "    def __init__(self, input_dir, output_dir, min_hu=-1000, max_hu=2000):\n",
        "        self.input_dir = Path(input_dir)\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.min_hu = min_hu\n",
        "        self.max_hu = max_hu\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def load_npy(self, file_path):\n",
        "        \"\"\"Safe load numpy file\"\"\"\n",
        "        if file_path.exists():\n",
        "            return np.load(file_path)\n",
        "        return None\n",
        "\n",
        "    def clip_and_rescale_ct(self, ct_array):\n",
        "        \"\"\"Clip HU and Rescale to [0, 1]\"\"\"\n",
        "        # 1. Clip\n",
        "        clipped = np.clip(ct_array, self.min_hu, self.max_hu)\n",
        "        # 2. Rescale Min-Max to [0, 1]\n",
        "        rescaled = (clipped - self.min_hu) / (self.max_hu - self.min_hu)\n",
        "        return rescaled.astype(np.float32)\n",
        "\n",
        "    def normalize_dose(self, dose_array):\n",
        "        \"\"\"Normalize Dose to [0, 1]\"\"\"\n",
        "        if dose_array.max() > 0:\n",
        "            return (dose_array / dose_array.max()).astype(np.float32)\n",
        "        return dose_array.astype(np.float32)\n",
        "\n",
        "    def augment_data(self, ct, dose, mask):\n",
        "        \"\"\"Random Rotation & Flip\"\"\"\n",
        "        # Random Rotate (-15 to 15 deg)\n",
        "        if np.random.rand() > 0.5:\n",
        "            angle = np.random.uniform(-15, 15)\n",
        "            # Use order=1 (linear) for CT/Dose, order=0 (nearest) for Mask\n",
        "            ct = rotate(ct, angle, axes=(1, 2), reshape=False, order=1)\n",
        "            dose = rotate(dose, angle, axes=(1, 2), reshape=False, order=1)\n",
        "            mask = rotate(mask, angle, axes=(1, 2), reshape=False, order=0)\n",
        "\n",
        "        # Random Flip\n",
        "        if np.random.rand() > 0.5:\n",
        "            axis = np.random.choice([0, 1, 2])\n",
        "            ct = np.flip(ct, axis=axis)\n",
        "            dose = np.flip(dose, axis=axis)\n",
        "            mask = np.flip(mask, axis=axis)\n",
        "\n",
        "        return ct, dose, mask\n",
        "\n",
        "    def visualize(self, ct_orig, dose_orig, ct_new, dose_new, save_path):\n",
        "        \"\"\"Compare Before vs After\"\"\"\n",
        "        mid_slice = ct_orig.shape[0] // 2\n",
        "\n",
        "        fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "        # Original\n",
        "        ax[0,0].imshow(ct_orig[mid_slice], cmap='gray')\n",
        "        ax[0,0].set_title(f\"Original CT (HU {int(ct_orig.min())} to {int(ct_orig.max())})\")\n",
        "        ax[0,1].imshow(dose_orig[mid_slice], cmap='jet')\n",
        "        ax[0,1].set_title(f\"Original Dose (Max {dose_orig.max():.2f} Gy)\")\n",
        "\n",
        "        # Preprocessed\n",
        "        ax[1,0].imshow(ct_new[mid_slice], cmap='gray')\n",
        "        ax[1,0].set_title(f\"Norm CT (0.0 - 1.0)\")\n",
        "        ax[1,1].imshow(dose_new[mid_slice], cmap='jet')\n",
        "        ax[1,1].set_title(f\"Norm Dose (0.0 - 1.0)\")\n",
        "\n",
        "        for a in ax.flatten(): a.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "    def process_all(self, augment=False):\n",
        "        \"\"\"Main processing loop\"\"\"\n",
        "        patients = [d for d in self.input_dir.iterdir() if d.is_dir()]\n",
        "        print(f\"üîÑ Found {len(patients)} patients to process.\")\n",
        "\n",
        "        for patient_dir in patients:\n",
        "            pid = patient_dir.name\n",
        "            print(f\"‚û°Ô∏è Processing: {pid}\")\n",
        "\n",
        "            # 1. Load Data\n",
        "            ct = self.load_npy(patient_dir / \"CT_raw.npy\")\n",
        "            dose = self.load_npy(patient_dir / \"Dose_raw.npy\")\n",
        "            mask = self.load_npy(patient_dir / \"Combined_Mask.npy\")\n",
        "\n",
        "            if ct is None or dose is None:\n",
        "                print(f\"‚ö†Ô∏è Missing CT or Dose for {pid}, skipping.\")\n",
        "                continue\n",
        "\n",
        "            if mask is None: # Create empty mask if missing\n",
        "                mask = np.zeros_like(ct)\n",
        "\n",
        "            # 2. Preprocessing\n",
        "            ct_norm = self.clip_and_rescale_ct(ct)\n",
        "            dose_norm = self.normalize_dose(dose)\n",
        "            mask_bin = (mask > 0.5).astype(np.float32)\n",
        "\n",
        "            # 3. Augmentation (Optional)\n",
        "            if augment:\n",
        "                ct_norm, dose_norm, mask_bin = self.augment_data(ct_norm, dose_norm, mask_bin)\n",
        "\n",
        "            # 4. Save\n",
        "            save_p = self.output_dir / pid\n",
        "            save_p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            np.save(save_p / \"CT_norm.npy\", ct_norm)\n",
        "            np.save(save_p / \"Dose_norm.npy\", dose_norm)\n",
        "            np.save(save_p / \"Mask_norm.npy\", mask_bin)\n",
        "\n",
        "            # 5. Visualize Check\n",
        "            self.visualize(ct, dose, ct_norm, dose_norm, save_p / \"check_preprocessing.png\")\n",
        "\n",
        "        print(\"‚úÖ All Training Data Prepared!\")\n",
        "\n",
        "# ================= RUN =================\n",
        "if __name__ == \"__main__\":\n",
        "    # Path ‡∏à‡∏≤‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "    INPUT_DIR = \"/content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/Data_numpy/v2/Predict\"\n",
        "\n",
        "    # Path ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ó‡∏£‡∏ô (Normalized Data)\n",
        "    OUTPUT_TRAIN_DIR = \"/content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/Data_numpy/v2/Data_Train_Ready\"\n",
        "\n",
        "    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n",
        "    prep = BrachyTrainingPrep(INPUT_DIR, OUTPUT_TRAIN_DIR)\n",
        "    prep.process_all(augment=False) # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô True ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏´‡∏°‡∏∏‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
      ],
      "metadata": {
        "id": "x4qBt4Eyt3gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1787e74-3f66-45cd-bcb6-662bb031fecd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Found 1 patients to process.\n",
            "‚û°Ô∏è Processing: FSD1_1\n",
            "‚úÖ All Training Data Prepared!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PREDICTION FUNCTION\n",
        "\n",
        "‡∏£‡∏ß‡∏° model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"
      ],
      "metadata": {
        "id": "n6Qxk2VtK3Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ‡πÅ‡∏Å‡πâ Path ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "FILE_PATH = \"/content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/best_model_FSD.pth\"\n",
        "\n",
        "if os.path.exists(FILE_PATH):\n",
        "    size_mb = os.path.getsize(FILE_PATH) / (1024 * 1024)\n",
        "    print(f\"üì¶ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Drive: {size_mb:.2f} MB\")\n",
        "else:\n",
        "    print(\"‚ùå ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠! ‡πÄ‡∏ä‡πá‡∏Ñ Path ‡∏î‡∏µ‡πÜ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IebJYLk3NO8f",
        "outputId": "bf3c128e-e4e1-47df-e3ff-aa1420b7523a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Drive: 69.35 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/best_model_FSD.pth\"\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(MODEL_PATH) as z:\n",
        "        print(\"‚úÖ ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô Zip ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢)\")\n",
        "        print(f\"‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô: {z.namelist()[:5]}\") # ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏¥‡πâ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏°‡∏≤‡∏î‡∏π\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏±‡∏á‡∏Ñ‡∏£‡∏±‡∏ö! (Bad Zip File) - ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà‡∏™‡∏ñ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error ‡∏≠‡∏∑‡πà‡∏ô‡πÜ: {e}\")"
      ],
      "metadata": {
        "id": "XFgrI2zAOXQn",
        "outputId": "f87610fc-75af-4f03-959b-039160382498",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô Zip ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢)\n",
            "‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô: ['best_model_FSD/data.pkl', 'best_model_FSD/byteorder', 'best_model_FSD/data/0', 'best_model_FSD/data/1', 'best_model_FSD/data/10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "\n",
        "# ================= 1. MODEL ARCHITECTURE (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) =================\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        b, c, _, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class SEResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, downsample=None):\n",
        "        super(SEResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size, stride=1, padding=padding)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        self.se = SEBlock(out_channels)\n",
        "        self.downsample = downsample\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None: identity = self.downsample(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.se(out)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "def crop_to_match(tensor, target_tensor):\n",
        "    diff_depth = tensor.size(2) - target_tensor.size(2)\n",
        "    diff_height = tensor.size(3) - target_tensor.size(3)\n",
        "    diff_width = tensor.size(4) - target_tensor.size(4)\n",
        "    if diff_depth < 0 or diff_height < 0 or diff_width < 0: return tensor\n",
        "    return tensor[:, :,\n",
        "                  diff_depth//2 : tensor.size(2)-diff_depth//2,\n",
        "                  diff_height//2 : tensor.size(3)-diff_height//2,\n",
        "                  diff_width//2 : tensor.size(4)-diff_width//2]\n",
        "\n",
        "class Cascade3DUNet(nn.Module):\n",
        "    def __init__(self, in_channels=2, num_classes=1):\n",
        "        super(Cascade3DUNet, self).__init__()\n",
        "        self.input_projection = nn.Conv3d(in_channels, 32, kernel_size=1)\n",
        "        self.encoder1 = SEResidualBlock(32, 32)\n",
        "        self.encoder2 = SEResidualBlock(32, 64, downsample=nn.Conv3d(32, 64, kernel_size=1))\n",
        "        self.encoder3 = SEResidualBlock(64, 128, downsample=nn.Conv3d(64, 128, kernel_size=1))\n",
        "        self.encoder4 = SEResidualBlock(128, 256, downsample=nn.Conv3d(128, 256, kernel_size=1))\n",
        "        self.encoder5 = SEResidualBlock(256, 512, downsample=nn.Conv3d(256, 512, kernel_size=1))\n",
        "        self.decoder4 = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2)\n",
        "        self.decoder4_conv = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n",
        "        self.decoder3 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
        "        self.decoder3_conv = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n",
        "        self.decoder2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
        "        self.decoder2_conv = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n",
        "        self.decoder1 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
        "        self.decoder1_conv = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n",
        "        self.proj4 = nn.Conv3d(256, 256, kernel_size=1)\n",
        "        self.proj3 = nn.Conv3d(128, 128, kernel_size=1)\n",
        "        self.proj2 = nn.Conv3d(64, 64, kernel_size=1)\n",
        "        self.proj1 = nn.Conv3d(32, 32, kernel_size=1)\n",
        "        self.final_conv = nn.Conv3d(32, num_classes, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(F.max_pool3d(enc1, 2))\n",
        "        enc3 = self.encoder3(F.max_pool3d(enc2, 2))\n",
        "        enc4 = self.encoder4(F.max_pool3d(enc3, 2))\n",
        "        enc5 = self.encoder5(F.max_pool3d(enc4, 2))\n",
        "        dec4 = self.decoder4(enc5)\n",
        "        dec4 = self.decoder4_conv(dec4)\n",
        "        dec4 = crop_to_match(dec4, enc4) + self.proj4(enc4)\n",
        "        dec3 = self.decoder3(dec4)\n",
        "        dec3 = self.decoder3_conv(dec3)\n",
        "        dec3 = crop_to_match(dec3, enc3) + self.proj3(enc3)\n",
        "        dec2 = self.decoder2(dec3)\n",
        "        dec2 = self.decoder2_conv(dec2)\n",
        "        dec2 = crop_to_match(dec2, enc2) + self.proj2(enc2)\n",
        "        dec1 = self.decoder1(dec2)\n",
        "        dec1 = self.decoder1_conv(dec1)\n",
        "        dec1 = crop_to_match(dec1, enc1) + self.proj1(enc1)\n",
        "        return torch.sigmoid(self.final_conv(dec1))\n",
        "\n",
        "# ================= 2. COPY & LOAD FUNCTION =================\n",
        "def load_robust_model(drive_path):\n",
        "    print(f\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á Copy ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Drive ‡∏°‡∏≤‡∏ó‡∏µ‡πà Colab (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Sync)...\")\n",
        "\n",
        "    # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Colab (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Drive)\n",
        "    local_path = \"/content/temp_best_model.pth\"\n",
        "\n",
        "    try:\n",
        "        # ‡∏•‡∏≠‡∏á Copy\n",
        "        shutil.copyfile(drive_path, local_path)\n",
        "        print(f\"‚úÖ Copy ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏Ç‡∏ô‡∏≤‡∏î: {os.path.getsize(local_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Copy ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô! ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÜ: {e}\")\n",
        "        return None\n",
        "\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Local\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = Cascade3DUNet(in_channels=2, num_classes=1).to(device)\n",
        "\n",
        "    print(f\"üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å: {local_path}\")\n",
        "    try:\n",
        "        # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö map_location='cpu' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô\n",
        "        checkpoint = torch.load(local_path, map_location=device)\n",
        "\n",
        "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        else:\n",
        "            model.load_state_dict(checkpoint)\n",
        "\n",
        "        print(\"üéâ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß (‡πÄ‡∏¢‡πâ!)\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ‡∏¢‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}\")\n",
        "        print(\"‡∏™‡∏£‡∏∏‡∏õ: ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≠‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà (‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô Drive)\")\n",
        "        return None\n",
        "\n",
        "# ================= 3. TEST RUN =================\n",
        "if __name__ == \"__main__\":\n",
        "    # ‡πÉ‡∏™‡πà Path ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "    DRIVE_MODEL_PATH = \"/content/drive/MyDrive/Medical Physics_PSCM05 (M. Sc.)/code/model/best_model_FSD.pth\"\n",
        "\n",
        "    loaded_model = load_robust_model(DRIVE_MODEL_PATH)"
      ],
      "metadata": {
        "id": "VZVngvt2KI8s",
        "outputId": "12bbe695-b7d4-4bce-e126-9dbdb598a790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á Copy ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Drive ‡∏°‡∏≤‡∏ó‡∏µ‡πà Colab (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Sync)...\n",
            "‚úÖ Copy ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏Ç‡∏ô‡∏≤‡∏î: 69.35 MB\n",
            "üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å: /content/temp_best_model.pth\n",
            "‚ùå ‡∏¢‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: PytorchStreamReader failed reading file data/101: invalid header or archive is corrupted\n",
            "‡∏™‡∏£‡∏∏‡∏õ: ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≠‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà (‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô Drive)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ul6NtYddNnaL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}